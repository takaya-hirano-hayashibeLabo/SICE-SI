\section{緒言}
Spiking Neural Network (SNN) は, Artificial Neural Network (ANN) と比較して, より脳の神経回路を模したモデルである\cite{TAVANAEI201947}.
脳のスパース性を導入することで, SNNはANNに比べて計算時のメモリ効率とエネルギー消費量を大幅に改善することが可能である.
そのため, 近年では第3のニューラルネットワークとして注目されている\cite{Henkes2024}.
SNNのスパース性は,その情報伝達方式によって再現される.
ANNは連続値を情報として伝達するのに対し, SNNはスパイクと呼ばれる0か1の情報のみを伝達する.
SNNではこのスパイクを時間的に連続に処理することで, スパース性を持つ脳の神経ダイナミクスを模倣している.

SNNはスパイクの時系列処理による動的特性を持つため, 時系列情報に対して高い処理能力を持つと考えられている\cite{zheng2024temporal}.
複雑な時系列情報は通常, 可変のタイムスケールと多量の周波数の情報を持つが, 脳は異なるタイムスケールの情報に対して頑健な処理が可能である\cite{10.1162/jocn_a_01615}.
例えば, 異なる速度で話す話者であっても, 人は容易にその認識ができることなどが挙げられる.
これは時系列処理において, マルチスケールの時間ダイナミクスに対して頑健な情報処理が重要であることを示唆している.

しかしながら, 既存のSNNのほとんどは, 異なる時間特性を活用が難しいLeaky Integrated-and-fire (LIF)モデルを用いた神経細胞ダイナミクスのモデル化を行っている\cite{dayan2003theoretical}.
LIFモデルが多く採用される理由は, 数理的に扱いやすく計算コストが低いためである.
一方で, LIFモデルでは過去の情報をどれだけ維持するかを表す時定数を固定する.
また, 時定数はハイパーパラメータであるため, モデルの設計者が扱う問題によって逐一設定する必要がある.
そのため, LIFモデルを用いたSNNは学習可能なタイムスケールが制限され, 豊富な時間的特性を表現することができない.

この課題に対し, 時定数に異質性をもたせることで対応する先行研究が多くみられる\cite{10.1145/3407197.3407225}\cite{ParametricSNN}.
時定数の異質性とは, 固定した値を用いるのではなく, SNNのニューロンごとにばらつきのある値を持たせることである.
Fangら\cite{ParametricSNN}はSNNの重みとバイアスに加え, 時定数も学習可能とする学習アルゴリズムを提案した.
これによって, 時定数が異質性を持ち, SNNの表現力が向上することや時定数が固定されたSNNよりも学習の収束が速いことを示した.
Zhengら\cite{zheng2024temporal}は, 学習可能な時定数の数を増やすことで, より複雑な時間表現を持つSNNを提案した.
結果として, 各ニューロンがより詳細かつ不均一な時間的特性を持つようになり, 音声, 視覚, 脳波認識に対して高い精度と頑健性を示した.

このような学習可能な時定数によってSNNの時間特性が向上する一方で, 学習データ量については問題があると考えられる.
学習を通じて時定数に異なる時間特性を持たせるためには, 異なる時間スケールのデータを学習時に与えなくてはならない.
このようなデータは時間的特性以外は同じ情報を持つため学習効率が悪化すると考えられる.
そこで, 本研究では時定数を含むSNNのパラメータの動的な変動を導入する.
これにより, 基準タイムスケールの学習のみによって, 多様なタイムスケールに対応可能なSNNを提案する.
結果として, パラメータを動的に変動させることで, 入力の時間変動に対するSNNの内部状態ダイナミクスの変化を抑制することが可能であった.
また, 動画分類タスクにおいて, 提案手法は既存のモデルと比較して, 少ない学習量で入力の時間変動に頑健な特性を示した.

